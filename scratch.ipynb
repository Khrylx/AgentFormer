{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rchoudhu/.conda/envs/agentformer/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import subprocess\n",
    "import argparse\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tepper_path = \"./datasets/tepper/Pedestrian_labels/0_frame.txt\"\n",
    "raw_data = np.genfromtxt(tepper_path, delimiter=',')\n",
    "seq_name = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't do any scaling yet.\n",
    "# only pedestrians.\n",
    "gt = raw_data\n",
    "frames = gt[:, 0].astype(np.float32).astype(int)\n",
    "fr_start, fr_end = frames.min(), frames.max()\n",
    "init_frame = fr_start\n",
    "num_fr = fr_end + 1 - fr_start\n",
    "past_frames = 8\n",
    "fut_frames = 12\n",
    "frame_skip = 1\n",
    "min_past_frames = 8\n",
    "min_future_frames = 12 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history_data(frame_idx):\n",
    "    data_list = []\n",
    "    for i in range(past_frames):\n",
    "        if frame_idx - i < init_frame:\n",
    "            data = []\n",
    "        data = gt[gt[:, 0] == (frame_idx - i) * frame_skip]\n",
    "        data_list.append(data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_future_data(frame_idx):\n",
    "    data_list = []\n",
    "    for i in range(1, fut_frames + 1):\n",
    "        data = gt[gt[:, 0] == frame_idx  + i * frame_skip]\n",
    "        data_list.append(data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(data):\n",
    "    id = []\n",
    "    for i in range(data.shape[0]):\n",
    "        id.append(data[i, 1].copy())\n",
    "    return id\n",
    "\n",
    "def get_valid_id(pre_data, fut_data):\n",
    "    cur_id = get_id(pre_data[0])\n",
    "    valid_id = []\n",
    "    for idx in cur_id:\n",
    "        exist_pre = [(False if isinstance(data, list) else (idx in data[:, 1])) for data in pre_data[:min_past_frames]]\n",
    "        exist_fut = [(False if isinstance(data, list) else (idx in data[:, 1])) for data in fut_data[:min_future_frames]]\n",
    "        if np.all(exist_pre) and np.all(exist_fut):\n",
    "            valid_id.append(idx)\n",
    "    return valid_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history_motion(data_list, valid_id):\n",
    "    motion = []\n",
    "    mask = []\n",
    "    for identity in valid_id:\n",
    "        mask_i = torch.zeros(past_frames)\n",
    "        past_coords = torch.zeros(past_frames, 3)\n",
    "        for frame_idx in range(past_frames):\n",
    "            past_data = data_list[frame_idx]\n",
    "            if len(past_data) > 0 and identity in past_data[:, 1]:\n",
    "                # Keep all indices (x, y, z), don't apply traj scale.\n",
    "                found_data = past_data[past_data[:, 1] == identity].squeeze()\n",
    "                past_coords[past_frames-1-frame_idx, :] = torch.from_numpy(found_data[[2,3,4]]).float()\n",
    "                mask_i[past_frames - 1 - frame_idx] = 1.0\n",
    "            elif frame_idx > 0:\n",
    "                past_coords[past_frames-1 - frame_idx, :] = past_coords[past_frames - frame_idx, :]\n",
    "            else:\n",
    "                raise ValueError('current id missing in the first frame!')\n",
    "        motion.append(past_coords)\n",
    "        mask.append(mask_i)\n",
    "    \n",
    "    return motion, mask\n",
    "\n",
    "def get_future_motion(data_list, valid_id):\n",
    "    motion = []\n",
    "    mask = []\n",
    "    for identity in valid_id:\n",
    "        mask_i = torch.zeros(fut_frames)\n",
    "        mask_i = torch.zeros(fut_frames)\n",
    "        pos_3d = torch.zeros([fut_frames, 3])\n",
    "        for j in range(fut_frames):\n",
    "            fut_data = data_list[j]              # cur_data\n",
    "            if len(fut_data) > 0 and identity in fut_data[:, 1]:\n",
    "                found_data = fut_data[fut_data[:, 1] == identity].squeeze()[[2,3,4]]\n",
    "                pos_3d[j, :] = torch.from_numpy(found_data).float()\n",
    "                mask_i[j] = 1.0\n",
    "            elif j > 0:\n",
    "                pos_3d[j, :] = pos_3d[j - 1, :]    # if none, copy from previous\n",
    "            else:\n",
    "                raise ValueError('current id missing in the first frame!')\n",
    "        motion.append(pos_3d)\n",
    "        mask.append(mask_i)\n",
    "    \n",
    "    return motion, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(frame_idx):\n",
    "    assert frame_idx - init_frame >= 0 and frame_idx - init_frame < num_fr\n",
    "\n",
    "    pre_data = get_history_data(frame_idx)\n",
    "    fut_data = get_future_data(frame_idx)\n",
    "    valid_id = get_valid_id(pre_data, fut_data)\n",
    "\n",
    "    if len(pre_data[0]) == 0 or len(fut_data[0]) == 0 or len(valid_id) == 0:\n",
    "        return None\n",
    "    pred_mask = None\n",
    "    heading = None\n",
    "    \n",
    "    pre_motion_3D, pre_motion_mask = get_history_motion(pre_data, valid_id)\n",
    "    fut_motion_3D, fut_motion_mask = get_future_motion(fut_data, valid_id)\n",
    "\n",
    "    data = {\n",
    "        'pre_motion_3D': pre_motion_3D,\n",
    "        'fut_motion_3D': fut_motion_3D,\n",
    "        'fut_motion_mask': fut_motion_mask,\n",
    "        'pre_motion_mask': pre_motion_mask,\n",
    "        'pre_data': pre_data,\n",
    "        'fut_data': fut_data,\n",
    "        'heading': heading,\n",
    "        'valid_id': valid_id,\n",
    "        'pred_mask': pred_mask,\n",
    "        'scene_map': None,\n",
    "        'seq': seq_name,\n",
    "        'frame': frame_idx\n",
    "    }\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_motion_3D': [tensor([[-13.6900,   9.6600,   0.0000],\n",
       "          [-14.4000,   8.7300,   0.0000],\n",
       "          [-15.0100,   8.2200,   0.0000],\n",
       "          [-15.8200,   7.0900,   0.0000],\n",
       "          [-16.6100,   6.7400,   0.0000],\n",
       "          [-17.2800,   6.0200,   0.0000],\n",
       "          [-18.4300,   4.8000,   0.0000],\n",
       "          [-19.5200,   3.8000,   0.0000]]),\n",
       "  tensor([[177.7100,  43.5800,   0.0000],\n",
       "          [177.7900,  43.3000,   0.0000],\n",
       "          [177.2500,  42.8400,   0.0000],\n",
       "          [176.6100,  42.1900,   0.0000],\n",
       "          [176.0800,  41.7300,   0.0000],\n",
       "          [175.9700,  41.5400,   0.0000],\n",
       "          [175.9500,  40.8300,   0.0000],\n",
       "          [175.4100,  40.3700,   0.0000]])],\n",
       " 'fut_motion_3D': [tensor([[-20.5600,   3.0100,   0.0000],\n",
       "          [-21.4100,   2.4500,   0.0000],\n",
       "          [-22.1400,   1.5200,   0.0000],\n",
       "          [-22.9100,   0.6100,   0.0000],\n",
       "          [-23.9100,  -0.1200,   0.0000],\n",
       "          [-24.4100,  -1.1500,   0.0000],\n",
       "          [-25.5100,  -2.0800,   0.0000],\n",
       "          [-26.1200,  -3.3100,   0.0000],\n",
       "          [-27.5400,  -4.0900,   0.0000],\n",
       "          [-28.4800,  -5.1700,   0.0000],\n",
       "          [-29.2100,  -5.8700,   0.0000],\n",
       "          [-30.1200,  -6.4100,   0.0000]]),\n",
       "  tensor([[175.5000,  40.0800,   0.0000],\n",
       "          [175.0700,  39.8100,   0.0000],\n",
       "          [174.6000,  39.6900,   0.0000],\n",
       "          [173.1300,  38.9700,   0.0000],\n",
       "          [171.1700,  38.2800,   0.0000],\n",
       "          [169.6700,  37.7200,   0.0000],\n",
       "          [167.7200,  37.0400,   0.0000],\n",
       "          [165.7500,  36.5000,   0.0000],\n",
       "          [163.9300,  36.0100,   0.0000],\n",
       "          [162.5600,  35.6500,   0.0000],\n",
       "          [161.2300,  35.1400,   0.0000],\n",
       "          [160.2200,  34.7100,   0.0000]])],\n",
       " 'fut_motion_mask': [tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])],\n",
       " 'pre_motion_mask': [tensor([1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 1.])],\n",
       " 'pre_data': [array([[ 4.0000e+03,  1.4000e+01, -1.9520e+01,  3.8000e+00,  0.0000e+00],\n",
       "         [ 4.0000e+03,  1.5000e+01,  1.7541e+02,  4.0370e+01,  0.0000e+00]]),\n",
       "  array([[3999.  ,   14.  ,  -18.43,    4.8 ,    0.  ],\n",
       "         [3999.  ,   15.  ,  175.95,   40.83,    0.  ]]),\n",
       "  array([[3998.  ,   14.  ,  -17.28,    6.02,    0.  ],\n",
       "         [3998.  ,   15.  ,  175.97,   41.54,    0.  ]]),\n",
       "  array([[3997.  ,   14.  ,  -16.61,    6.74,    0.  ],\n",
       "         [3997.  ,   15.  ,  176.08,   41.73,    0.  ]]),\n",
       "  array([[3996.  ,   14.  ,  -15.82,    7.09,    0.  ],\n",
       "         [3996.  ,   15.  ,  176.61,   42.19,    0.  ]]),\n",
       "  array([[3995.  ,   14.  ,  -15.01,    8.22,    0.  ],\n",
       "         [3995.  ,   15.  ,  177.25,   42.84,    0.  ]]),\n",
       "  array([[3994.  ,   14.  ,  -14.4 ,    8.73,    0.  ],\n",
       "         [3994.  ,   15.  ,  177.79,   43.3 ,    0.  ]]),\n",
       "  array([[3993.  ,   14.  ,  -13.69,    9.66,    0.  ],\n",
       "         [3993.  ,   15.  ,  177.71,   43.58,    0.  ]])],\n",
       " 'fut_data': [array([[ 4.001e+03,  1.400e+01, -2.056e+01,  3.010e+00,  0.000e+00],\n",
       "         [ 4.001e+03,  1.500e+01,  1.755e+02,  4.008e+01,  0.000e+00]]),\n",
       "  array([[ 4.0020e+03,  1.4000e+01, -2.1410e+01,  2.4500e+00,  0.0000e+00],\n",
       "         [ 4.0020e+03,  1.5000e+01,  1.7507e+02,  3.9810e+01,  0.0000e+00]]),\n",
       "  array([[ 4.003e+03,  1.400e+01, -2.214e+01,  1.520e+00,  0.000e+00],\n",
       "         [ 4.003e+03,  1.500e+01,  1.746e+02,  3.969e+01,  0.000e+00]]),\n",
       "  array([[ 4.0040e+03,  1.4000e+01, -2.2910e+01,  6.1000e-01,  0.0000e+00],\n",
       "         [ 4.0040e+03,  1.5000e+01,  1.7313e+02,  3.8970e+01,  0.0000e+00]]),\n",
       "  array([[ 4.0050e+03,  1.4000e+01, -2.3910e+01, -1.2000e-01,  0.0000e+00],\n",
       "         [ 4.0050e+03,  1.5000e+01,  1.7117e+02,  3.8280e+01,  0.0000e+00]]),\n",
       "  array([[ 4.0060e+03,  1.4000e+01, -2.4410e+01, -1.1500e+00,  0.0000e+00],\n",
       "         [ 4.0060e+03,  1.5000e+01,  1.6967e+02,  3.7720e+01,  0.0000e+00]]),\n",
       "  array([[ 4.0070e+03,  1.4000e+01, -2.5510e+01, -2.0800e+00,  0.0000e+00],\n",
       "         [ 4.0070e+03,  1.5000e+01,  1.6772e+02,  3.7040e+01,  0.0000e+00]]),\n",
       "  array([[ 4.0080e+03,  1.4000e+01, -2.6120e+01, -3.3100e+00,  0.0000e+00],\n",
       "         [ 4.0080e+03,  1.5000e+01,  1.6575e+02,  3.6500e+01,  0.0000e+00]]),\n",
       "  array([[4009.  ,   14.  ,  -27.54,   -4.09,    0.  ],\n",
       "         [4009.  ,   15.  ,  163.93,   36.01,    0.  ]]),\n",
       "  array([[4010.  ,   14.  ,  -28.48,   -5.17,    0.  ],\n",
       "         [4010.  ,   15.  ,  162.56,   35.65,    0.  ]]),\n",
       "  array([[4011.  ,   14.  ,  -29.21,   -5.87,    0.  ],\n",
       "         [4011.  ,   15.  ,  161.23,   35.14,    0.  ]]),\n",
       "  array([[4012.  ,   14.  ,  -30.12,   -6.41,    0.  ],\n",
       "         [4012.  ,   15.  ,  160.22,   34.71,    0.  ]])],\n",
       " 'heading': None,\n",
       " 'valid_id': [14.0, 15.0],\n",
       " 'pred_mask': None,\n",
       " 'scene_map': None,\n",
       " 'seq': '0',\n",
       " 'frame': 4000}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Great, dataloader is deon. Now, how do we include it in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay dataloader is essentially done. Next, need to get the thing training with it.\n",
    "# ugh its so much work"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0751bac17592ed945c13c689aa206d48b6947211fbf78cf0843fc7df780069d5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('agentformer': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
